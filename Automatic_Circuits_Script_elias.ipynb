{"cells":[{"cell_type":"markdown","metadata":{"id":"P_2eFLrTH5_-"},"source":["# Automatic Circuit Discovery"]},{"cell_type":"markdown","source":["### Adapted from: https://colab.research.google.com/github/ArthurConmy/Easy-Transformer/blob/main/AutomaticCircuitDiscovery.ipynb"],"metadata":{"id":"Y2rTyR3n8wJf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2958,"status":"ok","timestamp":1674398503112,"user":{"displayName":"Chris Mathwin","userId":"10976055293495774480"},"user_tz":-660},"id":"hoq81zbVH6AA","outputId":"42aff2ca-b12c-489c-cbc3-6999cda03a32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n"]}],"source":["import os\n","\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    os.system(\"pip install git+https://github.com/ArthurConmy/Easy-Transformer.git\")\n","\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thBrJJf3H6AB"},"outputs":[],"source":["from typing import List, Tuple, Dict, Union, Optional, Callable, Any\n","from time import ctime\n","import einops\n","import torch\n","import numpy as np\n","from copy import deepcopy\n","from collections import OrderedDict\n","import pickle\n","from subprocess import call\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","if ipython is not None:\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")\n","from easy_transformer import EasyTransformer\n","from easy_transformer.utils_circuit_discovery import (\n","    evaluate_circuit,\n","    patch_all,\n","    direct_path_patching,\n","    logit_diff_io_s,\n","    Circuit,\n","    logit_diff_from_logits,\n","    get_datasets,\n",")\n","\n","from easy_transformer.ioi_utils import (\n","    path_patching,\n",")\n","\n","from tqdm import tqdm\n","\n","from easy_transformer.experiments import (\n","    get_act_hook,\n",")\n","from easy_transformer.ioi_utils import (\n","    show_pp,\n",")\n","from easy_transformer.ioi_dataset import IOIDataset\n","import os\n","\n","file_prefix = \"archive/\" if os.path.exists(\"archive\") else \"\"\n","\n","from easy_transformer.experiments import (\n","    ExperimentMetric,\n","    AblationConfig,\n","    EasyAblation,\n","    EasyPatching,\n","    PatchingConfig,\n",")\n","\n","from easy_transformer.ioi_circuit_extraction import (\n","    get_circuit_replacement_hook,\n",")"]},{"cell_type":"markdown","metadata":{"id":"grGmLjvxH6AB"},"source":["### Load the model in"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qx-RpADYH6AC"},"outputs":[],"source":["model_name = \"gpt2\"\n","model = EasyTransformer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{"id":"e52ifKqvH6AC"},"source":["### Creating a dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgVWG8vuH6AC"},"outputs":[],"source":["templates = [\n","    \"So {name} is a really great friend, isn't\",\n","    \"So {name} is such a good cook, isn't\",\n","    \"So {name} is a very good athlete, isn't\",\n","    \"So {name} is a really nice person, isn't\",\n","    \"So {name} is such a funny person, isn't\"\n","    ]\n","\n","male_names = [\n","    \"John\",\n","    \"David\",\n","    \"Mark\",\n","    \"Paul\",\n","    \"Ryan\",\n","    \"Gary\",\n","    \"Jack\",\n","    \"Sean\",\n","    \"Carl\",\n","    \"Joe\",    \n","]\n","female_names = [\n","    \"Mary\",\n","    \"Lisa\",\n","    \"Anna\",\n","    \"Sarah\",\n","    \"Amy\",\n","    \"Carol\",\n","    \"Karen\",\n","    \"Susan\",\n","    \"Julie\",\n","    \"Judy\"\n","]\n","\n","sentences = []\n","answers = []\n","wrongs = []\n","\n","responses = [' he', ' she']\n","\n","count = 0\n","\n","for name in male_names + female_names:\n","    for template in templates:\n","        cur_sentence = template.format(name = name)\n","        sentences.append(cur_sentence)\n","\n","batch_size = len(sentences)\n","\n","count = 0\n","\n","for _ in range(batch_size):\n","    if count < (0.5 * len(sentences)):\n","        answers.append(responses[0])\n","        wrongs.append(responses[1])\n","        count += 1\n","    else:\n","        answers.append(responses[1])\n","        wrongs.append(responses[0])\n","\n","tokens = model.to_tokens(sentences, prepend_bos = True)\n","answers = torch.tensor(model.tokenizer(answers)[\"input_ids\"]).squeeze()\n","wrongs = torch.tensor(model.tokenizer(wrongs)[\"input_ids\"]).squeeze()"]},{"cell_type":"markdown","metadata":{"id":"ScFQM7UhH6AD"},"source":["### Make the positions labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5Y5UhZ1H6AD"},"outputs":[],"source":["for i, token in enumerate(model.to_str_tokens(tokens[0])):\n","    print(i, token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pjl1p-aH6AD"},"outputs":[],"source":["positions = OrderedDict()\n","\n","ones = torch.ones(size = (batch_size,)).long()\n","\n","positions[\"name\"] = ones.clone() * 2\n","positions[\"is\"] = ones.clone() * 3\n","positions[\"person\"] = ones.clone() * 7\n","positions[\"isn\"] = ones.clone() * 9\n","positions[\"'t\"] = ones.clone() * 10"]},{"cell_type":"markdown","metadata":{"id":"HvVtNpUkH6AE"},"source":["### Making a baseline dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4hJw8blH6AE"},"outputs":[],"source":["baseline_data = tokens.clone()\n","baseline_data[0] = model.to_tokens(\"That person is a really great friend, isn't\", prepend_bos = True)\n","baseline_data = einops.repeat(baseline_data[0], \"seq -> batch seq\", batch = batch_size)"]},{"cell_type":"markdown","metadata":{"id":"eOH_nIxFH6AE"},"source":["### Define the metric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_NGhfdVH6AE"},"outputs":[],"source":["def pronoun_metric(model, tokens = tokens):\n","    logits = model(tokens)\n","    logits_on_correct = logits[torch.arange(batch_size), -1, answers]\n","    logits_on_wrong = logits[torch.arange(batch_size), -1, wrongs]\n","    result = torch.mean(logits_on_correct - logits_on_wrong)\n","    return result.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TC57qh0gml5A"},"outputs":[],"source":["model_performance = pronoun_metric(model, tokens)"]},{"cell_type":"markdown","metadata":{"id":"W_OSrW3oH6AE"},"source":["### Make the Circuit object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjLsuIwWH6AE"},"outputs":[],"source":["h = Circuit(\n","    model,\n","    metric = pronoun_metric,\n","    orig_data = tokens,\n","    new_data = baseline_data,\n","    threshold = 0.015,\n","    dataset = tokens,\n","    orig_positions = positions,\n","    new_positions = positions\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AhwSjJCH6AF"},"outputs":[],"source":["while h.current_node is not None:    \n","    h.eval(show_graphics=True, verbose=True)\n","\n","    a = h.show()\n","    # save digraph object\n","    with open(file_prefix + \"hypothesis_tree.dot\", \"w\") as f:\n","        f.write(a.source)\n","\n","    # convert to png\n","    call(\n","        [\n","            \"dot\",\n","            \"-Tpng\",\n","            \"hypothesis_tree.dot\",\n","            \"-o\",\n","            file_prefix + f\"gpt2_hypothesis_tree_{ctime()}.png\",\n","            \"-Gdpi=600\",\n","        ]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23rcomtrH6AF"},"outputs":[],"source":["h.show()"]},{"cell_type":"markdown","metadata":{"id":"Hko9I8JpoCgc"},"source":["## Evaluating the Circuit's Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzAcST2Kji2g"},"outputs":[],"source":["# From: https://github.com/ArthurConmy/Automatic-Circuit-Discovery/blob/main/easy_transformer/utils_circuit_discovery.py\n","def get_hook_tuple(layer, head_idx, comp=None, input=False, model_layers=12):\n","    \"\"\"Very cursed\"\"\"\n","    \"\"\"warning, built for 12 layer models\"\"\"\n","\n","    if layer == -1:\n","        assert head_idx is None, head_idx\n","        assert comp is None, comp\n","        return (\"blocks.0.hook_resid_pre\", None)\n","\n","    if comp is None:\n","        if head_idx is None:\n","            if layer < model_layers:\n","                if input:\n","                    return (f\"blocks.{layer}.hook_resid_mid\", None)\n","                else:\n","                    return (f\"blocks.{layer}.hook_mlp_out\", None)\n","            else:\n","                assert layer == model_layers\n","                return (f\"blocks.{layer-1}.hook_resid_post\", None)\n","        else:\n","            return (f\"blocks.{layer}.attn.hook_result\", head_idx)\n","\n","    else:  # I think the QKV case here is quite different because this is INPUT to a component, not output\n","        assert comp in [\"q\", \"k\", \"v\"]\n","        assert head_idx is not None\n","        return (f\"blocks.{layer}.attn.hook_{comp}_input\", head_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QcKtcFuRjWu3"},"outputs":[],"source":["# From: https://github.com/ArthurConmy/Automatic-Circuit-Discovery/blob/main/easy_transformer/utils_circuit_discovery.py\n","def make_base_receiver_sender_objects(\n","    important_nodes,\n","):\n","    base_initial_senders = []\n","    base_receivers_to_senders = {}\n","\n","    for receiver in important_nodes:\n","        hook = get_hook_tuple(receiver.layer, receiver.head, input=True)\n","\n","        for sender_child, _, comp in receiver.children:\n","            if comp in [\"v\", \"k\", \"q\"]:\n","                qkv_hook = get_hook_tuple(receiver.layer, receiver.head, comp)\n","                if qkv_hook not in base_receivers_to_senders:\n","                    base_receivers_to_senders[qkv_hook] = []\n","                sender_hook = get_hook_tuple(sender_child.layer, sender_child.head)\n","                base_receivers_to_senders[qkv_hook].append(\n","                    (sender_hook[0], sender_hook[1], sender_child.position)\n","                )\n","\n","            else:\n","                if hook not in base_receivers_to_senders:\n","                    base_receivers_to_senders[hook] = []\n","                sender_hook = get_hook_tuple(sender_child.layer, sender_child.head)\n","                base_receivers_to_senders[hook].append(\n","                    (sender_hook[0], sender_hook[1], sender_child.position)\n","                )\n","\n","    return base_receivers_to_senders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgqZl_gGgmLB"},"outputs":[],"source":["# From: https://github.com/ArthurConmy/Automatic-Circuit-Discovery/blob/main/easy_transformer/utils_circuit_discovery.py\n","def evaluate_circuit(h):\n","    if h.current_node is not None:\n","        raise NotImplementedError(\"Make circuit full\")\n","\n","    receivers_to_senders = make_base_receiver_sender_objects(h.important_nodes)\n","\n","    # what we do here is make sure that the ONLY embed objects that are set to their values on the original dataset are the ones that are in the circuit\n","    initial_receivers_to_senders: List[\n","        Tuple[Tuple[str, Optional[int]], Tuple[str, Optional[int], str]]\n","    ] = []\n","    for node in h.important_nodes:\n","        for child, _, _2 in node.children:\n","            if child.layer == -1:\n","                initial_receivers_to_senders.append(\n","                    (\n","                        (\"blocks.0.hook_resid_pre\", None),\n","                        (\"blocks.0.hook_resid_pre\", None, node.position),\n","                    )\n","                )\n","    assert (\n","        len(initial_receivers_to_senders) > 0\n","    ), \"Need at least one embedding present!!!\"\n","\n","    initial_receivers_to_senders = list(set(initial_receivers_to_senders))\n","\n","    for pos in h.orig_positions:\n","        assert torch.allclose(\n","            h.orig_positions[pos], h.new_positions[pos]\n","        ), \"Data must be the same for all positions\"\n","\n","    model = direct_path_patching(\n","        model=h.model,\n","        orig_data=h.new_data,  # NOTE these are different\n","        new_data=h.orig_data,\n","        initial_receivers_to_senders=initial_receivers_to_senders,\n","        receivers_to_senders=receivers_to_senders,\n","        orig_positions=h.orig_positions,  # tensor of shape (batch_size,)\n","        new_positions=h.new_positions,\n","        orig_cache=None,\n","        new_cache=None,\n","    )\n","    return h.metric(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roggKZjIjVfD"},"outputs":[],"source":["circuit_performance = evaluate_circuit(h)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trKQkit-m-9l"},"outputs":[],"source":["circuit_percentage = 100*(circuit_performance / model_performance)\n","print(f\"Circuit performs {circuit_percentage:.2f}% as well as the model on this task and has {len(h.important_nodes)} heads.\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1jGUpQsAsb0rGyNzqoDCMjPXvFWTCxm3n","timestamp":1674381865167},{"file_id":"1V6mVLU1Ia42fXsygOnTOAhi47lvxgAqE","timestamp":1674318737083}]},"gpuClass":"premium","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"fb833273add3e7c60eb33c0608260b79a61e072ade6f02cc8d07b0a26eef8ab8"}}},"nbformat":4,"nbformat_minor":0}